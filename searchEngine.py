# -*- coding: utf-8 -*-
"""ahmet_mirza_duru_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-39pmgq2dhgUMl6gwRE2j3TPH77wp9bh
"""



#1-a
def getPage(url): #Everything comes from this code. Once you entered an url, it will give you an html code for that url that means a string.
  try:
    import urllib.request
    page = urllib.request.urlopen(url).read()
    return page.decode("utf-8")
  except:
    return ""

def linkExtracter(htmlContent):
  firstHref = htmlContent.find('a href')
  firstQuote = htmlContent.find('"',firstHref)+1
  secondQuote = htmlContent.find('"',firstQuote)
  urlLink = htmlContent[firstQuote:secondQuote]
  return urlLink , secondQuote

def allLinkExtracter(url):
  htmlContent = getPage(url)

  urlList = []
  while htmlContent.find('a href') != -1 :
    urlLink , secondQuote = linkExtracter(htmlContent)
    if urlLink.find('http') == -1:
      urlList.append(url + urlLink)
    else:
      urlList.append(urlLink)
    htmlContent = htmlContent[secondQuote:]
  return urlList

def keyWordExtractor(url):
  content = getPage(url).split()
  return content

def fullAutomaticIndexAdder(anyList) :
  anIndex = {}
  for links in anyList:
    keywordList = keyWordExtractor(links)
    for words in keywordList:
      if words not in anIndex:
        anIndex[words] = [[links]]
      else:
        if links not in anIndex[words][0]:
          anIndex[words][0].append(links)
  for keywords in anIndex:
    anIndex[keywords].append(len(anIndex[keywords][0]))
  return anIndex

def graphDesigner(anyList):
  myGraph = {}
  for elements in anyList:
    myGraph[elements] = allLinkExtracter(elements)
  return myGraph

def urlRanker(anyGraph):
  d = 0.8
  N = len(anyGraph)
  repetitionCount = 10
  ranks = {}

  for element in anyGraph:
    ranks[element] = 1/N
  for i in range(repetitionCount):
    newranks = {}
    for element in anyGraph:
      newrank = (1-d)/N
      for node in anyGraph:
        if node in anyGraph[node]:
          newrank = newrank + d*(ranks[node]/(len(anyGraph[element])+1))
      newranks[element] = newrank
    ranks = newranks
  return ranks


def crawl_web(url):
  toCrawl = [url]
  crawled = []
  while len(toCrawl) > 0 :
    processingUrl = toCrawl.pop()
    if processingUrl not in crawled:
      for links in allLinkExtracter(processingUrl):
        if links not in toCrawl:
          toCrawl.append(links)
      crawled.append(processingUrl)
      if len(crawled) > 100:
        break

  myIndex = fullAutomaticIndexAdder(crawled)
  myGraph = graphDesigner(crawled)
  myRanksIndex = urlRanker(myGraph)
  return myRanksIndex , myIndex


def lookUp(index , keyword ):
  if keyword in index:
    print('Keyword: ' + keyword)
    print(str(index[keyword][1]) + ' results found.')
    print('Urls:')
    for elements in index[keyword][0]:
      print(elements)
  else:
    print('Keyword: ' + str(keyword))
    print('0 results found.')


def lookUpLink(index , url) :
  urls = []
  for kw in index:
    for link in index[kw][0]:
      if link not in urls:
        urls.append(link)

  if url not in urls:
    print('Link: ' + str(url))
    print('0 ' + ' keyword found.')
  else:
    content = keyWordExtractor(url)
    keys = []
    for words in content:
      if words not in keys:
        keys.append(words)

    print('Link: ' + str(url))
    print( str(len(keys)) + ' keyword found.')
    for element in keys:
      print(element)


